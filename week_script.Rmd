---
title: "Priyanka's script"
output: html_document
---

# Load libraries and read in data
```{r}
library(tidyverse) # for everything else!
library(lubridate) # for dates!
library(fs)
```

# Create function to calculate variability

I've rewritten that other guy's function to instead just calculate this via tibble-wrangling :)

```{r}
calc_tRMSSD <- function(mood_data, timestamp_data){
  if (length(mood_data) < 2){
    return(NA)
  } else {
  
  # create tibble and make sure it's arranged by timestamp
  data_calc <- tibble(
    mood = mood_data,
    timestamp = timestamp_data
  ) %>% 
    arrange(timestamp)
  
  # get the difference in mood and time between days
  data_calc <- data_calc %>% 
    mutate(dtime = timestamp - lag(timestamp),
           dmood = mood - lag(mood)) %>% 
    filter(!is.na(dmood)) %>% 
    mutate(dtime = as.numeric(dtime))
  
  # calculate the tRMSSD value
  sqrt(1/nrow(data_calc)*sum((data_calc$dmood/data_calc$dtime)^2))
  }
}

```

## Actigraphy data
### Read in data
We're going to read in the calender_date as a character, because the timezone actually changes at some point and that makes the dates move! And we drop that entirely BECAUSE it makes it seem as if there were 23 hours from one measurement to the next etc but there isnt and it also makes it seem as if there were two measurements on the same date when that wasn't the case.

```{r, message=FALSE}
# get the csv files in a named vector
participant_data <- list.files(path = "data/raw/Actigraphy", pattern = "actigraphy.csv$", full.names = TRUE) %>% 
  set_names()


my_read <- function(filepath){
  read_csv(filepath, col_types = list(
    id = col_character(),
    calender_date = col_character()
  ))
}

# read them in and put in a data frame
raw_data_acti <- map_dfr(participant_data, my_read, .id = "csv_file")

# clean it up
raw_data_acti_clean <- raw_data_acti %>% 
  mutate(participant_id = str_extract(path_file(csv_file), "c\\d+")) %>% 
  select(-csv_file) %>% 
  relocate(participant_id)

```

### Clean data
We are 

- adding columns for the date, week, weekday, and adds a numeric timestamp (this just as the date as a number - it's probably number of days since 1 jan 1970 or something to that effect! :)  )
- for each participant, we count the number of days from they started, and then the number of corresponding weeks
- removing entries that are NA for the RA column

```{r}
acti_data <- raw_data_acti_clean %>% 
  mutate(calender_date = str_sub(calender_date, 1, -6), # strip away the time zone information
         calender_date = ymd_hms(calender_date),
         date = date(calender_date),
         date_as_number = as.numeric(date),
         weekday = wday(date, label = TRUE),
         year = year(date)) %>% 
  group_by(participant_id) %>% 
  mutate(days_relative_to_first_measurement = date_as_number - min(date_as_number),
         weeks_count_from_start = floor(days_relative_to_first_measurement / 7) + 1) %>% 
  filter(across(c(L5_onset, L5_activity, M10_onset, M10_activity, RA), ~!is.na(.))) %>%  # drop rows with no measurements!
  distinct() %>% # drop duplicate rows
  relocate(weeks_count_from_start, calender_date, date, weekday)

```


So this here below groups by week (a week is Mon-Sun) and participant id and then just calculates the tRMSSD 

```{r}
tRMSSD_actigraphy <- acti_data %>% 
  group_by(participant_id, weeks_count_from_start) %>% 
  summarise(across(c(L5_onset, L5_activity, M10_onset, M10_activity, RA), ~ calc_tRMSSD(.x, date_as_number))) %>%  
  rename_with(.cols = -c(participant_id, weeks_count_from_start), ~str_c("tRMSSD_", .)) %>% 
  arrange(participant_id, weeks_count_from_start)

write_csv(tRMSSD_actigraphy, "data/processed/tRMSSD_actigraphy.csv")
```
Make it long!

```{r}
tRMSSD_acti_w_group <- tRMSSD_actigraphy %>% 
  left_join(condition_info) %>% 
  filter(!is.na(Group)) 


wide_scores_acti <- tRMSSD_acti_w_group %>% 
  filter(weeks_count_from_start <= 10) %>% 
  pivot_wider(names_from = weeks_count_from_start, values_from = c(tRMSSD_L5_onset, tRMSSD_L5_activity, tRMSSD_M10_onset, tRMSSD_M10_activity, tRMSSD_RA))

write_csv(wide_scores_acti, "data/processed/wide_scores_acti.csv")
```

### Visualise actigraphy data
#### Join the group information

So in order to do this we want the information about the condition they were in! Yay!

We join with their group and then we drop the ones who don't have a group (there's like 4 of them - these are ppl who dropped out or were otherwise excluded)

```{r}
condition_info <- read_csv("data/COMET_group.csv") %>% 
  select(-`Participant ID`) %>% 
  mutate(Group = if_else(Group == 2, "low MDQ", "high MDQ")) %>% 
  rename(participant_id = ID)

tRMSSD_acti_w_group <- tRMSSD_actigraphy %>% 
  left_join(condition_info) %>% 
  filter(!is.na(Group)) 
```


#### Visualise the shit out of it
We exclude weeks after weeek 10

```{r}
tRMSSD_acti_weeks <- tRMSSD_acti_w_group %>% 
  filter(weeks_count_from_start <= 10) %>% 
  mutate(weeks_count_from_start = factor(weeks_count_from_start))
```

And NOW we can actually visualise it! Yay!


#### Naive line graph across EVERYTHING for RA

```{r}
tRMSSD_acti_weeks %>% 
  ggplot() +
    aes(x = weeks_count_from_start, y = tRMSSD_RA, color = Group) +
    geom_jitter(height = 0, width = 0.1, alpha = 0.5) +
    geom_line(aes(group = participant_id))
```

Let's make a similar one where we have facets for each of the measures.

We need a wrangling step first

```{r}
tRMSSD_acti_long <- tRMSSD_acti_weeks %>% 
  pivot_longer(-c(participant_id, Group, weeks_count_from_start)) %>% 
  rename(measure = name) %>% 
  mutate(measure = str_remove(measure, "tRMSSD_"))

tRMSSD_acti_long %>% 
  ggplot() +
    aes(x = weeks_count_from_start, y = value, color = Group) +
    geom_jitter(height = 0, width = 0.1, alpha = 0.5) +
    geom_line(aes(group = participant_id)) +
    facet_wrap(~measure, scales = "free")
```

#### do the averages

```{r}
tRMSSD_aves <- tRMSSD_acti_long %>% 
  group_by(Group, weeks_count_from_start, measure) %>% 
  summarise(ave_tRMSSD = mean(value, na.rm = TRUE))
  

tRMSSD_aves %>% 
  ggplot() +
    aes(x = weeks_count_from_start, y = ave_tRMSSD, color = Group) +
    geom_point(height = 0, width = 0.1, alpha = 0.5) +
    geom_line(aes(group = Group)) +
    facet_wrap(~measure, scales = "free")
```

TODO: this should have some sort of visualisation of the spread around the mean



#### Naive line graph w facets
```{r}
tRMSSD_acti_weeks %>% 
  ggplot() +
    aes(x = weeks_count_from_start, y = tRMSSD_RA, color = participant_id) +
    geom_jitter(height = 0, width = 0.1, alpha = 0.5) +
    geom_line(aes(group = participant_id)) +
    facet_wrap(~Group)
```



## PANAS
### Read in data
```{r, message=FALSE}
# get the csv files in a named vector
participant_data_panas <- list.files(path = "data/raw/PANAS", pattern = "PANAS.csv$", full.names = TRUE) %>% 
  set_names()

# read them in and put in a data frame
raw_data_panas <- map_df(participant_data_panas, read_csv, .id = "csv_file")

# clean it up
raw_data_panas_clean <- raw_data_panas %>% 
  mutate(participant_id = str_extract(path_file(csv_file), "c\\d+")) %>% 
  select(-csv_file) %>% 
  relocate(participant_id)
```

### Clean data
We are 

- adding columns for the date, week, weekday, and adds a numeric timestamp (this just as the date as a number - it's probably number of days since 1 jan 1970 or something to that effect! :)  )
- for each participant, we count the number of days from they started, and then the number of corresponding weeks

```{r}
panas_data <- raw_data_panas_clean %>% 
  mutate(date_time = str_c(testdate, testtime, sep = " "),
         date_time = dmy_hms(date_time),
         date = date(date_time),
         weekday = wday(date_time, label = TRUE),
         date_time_as_number = as.numeric(date_time),
         date_as_number = as.numeric(date)) %>% 
  group_by(participant_id) %>% 
  mutate(days_relative_to_first_measurement = date_as_number - min(date_as_number),
         weeks_count_from_start = floor(days_relative_to_first_measurement / 7) + 1) %>% 
  select(-c(testdate, testtime)) %>% 
  relocate(date_time, weekday, weeks_count_from_start)

```


So this here below groups by week (a week is Mon-Sun) and participant id and then just get 

```{r}
tRMSSD_panas <- panas_data %>% 
  group_by(participant_id, weeks_count_from_start) %>% 
  summarise(across(c(pos, neg, sum), ~ calc_tRMSSD(.x, date_time_as_number))) %>% 
  rename_with(.cols = -c(participant_id, weeks_count_from_start), ~str_c("tRMSSD_", .)) %>% 
  arrange(participant_id, weeks_count_from_start)

write_csv(tRMSSD_panas, "data/processed/tRMSSD_panas.csv")

```


Make it long!

```{r}
tRMSSD_panas_w_group <- tRMSSD_panas %>% 
  left_join(condition_info) %>% 
  filter(!is.na(Group)) 


wide_scores_panas <- tRMSSD_panas_w_group %>% 
  filter(weeks_count_from_start <= 10) %>% 
  pivot_wider(names_from = weeks_count_from_start, values_from = c(tRMSSD_pos, tRMSSD_neg, tRMSSD_sum))

write_csv(wide_scores_panas, "data/processed/wide_scores_panas.csv")

```

### Visualise PANAS data
#### Join the group information

So in order to do this we want the information about the condition they were in! Yay!

We join with their group and then we drop the ones who don't have a group (there's like 4 of them - these are ppl who dropped out or were otherwise excluded)

```{r}
condition_info <- read_csv("data/COMET_group_panas.csv") %>% 
  select(-`Participant ID`) %>% 
  mutate(Group = if_else(Group == 2, "low MDQ", "high MDQ")) %>% 
  rename(participant_id = ID)

tRMSSD_panas_w_group <- tRMSSD_panas %>% 
  left_join(condition_info) %>% 
  filter(!is.na(Group)) 
```


#### Visualise the shit out of it
We exclude weeks after week 10

```{r}
tRMSSD_panas_weeks <- tRMSSD_panas_w_group %>% 
  filter(weeks_count_from_start <= 10) %>% 
  mutate(weeks_count_from_start = factor(weeks_count_from_start))
```

And NOW we can actually visualise it! Yay!


#### Naive line graph across EVERYTHING for panas pos

```{r}
tRMSSD_panas_weeks %>% 
  ggplot() +
    aes(x = weeks_count_from_start, y = tRMSSD_pos, color = Group) +
    geom_jitter(height = 0, width = 0.1, alpha = 0.5) +
    geom_line(aes(group = participant_id))
```

Let's make a similar one where we have facets for each of the measures.

We need a wrangling step first

```{r}
tRMSSD_panas_long <- tRMSSD_panas_weeks %>% 
  pivot_longer(-c(participant_id, Group, weeks_count_from_start)) %>% 
  rename(measure = name) %>% 
  mutate(measure = str_remove(measure, "tRMSSD_"))

tRMSSD_panas_long %>% 
  ggplot() +
    aes(x = weeks_count_from_start, y = value, color = Group) +
    geom_jitter(height = 0, width = 0.1, alpha = 0.5) +
    geom_line(aes(group = participant_id)) +
    facet_wrap(~measure, scales = "free")
```

#### do the averages

```{r}
tRMSSD_panas_aves <- tRMSSD_panas_long %>% 
  group_by(Group, weeks_count_from_start, measure) %>% 
  summarise(ave_tRMSSD = mean(value, na.rm = TRUE))
  

tRMSSD_panas_aves %>% 
  ggplot() +
    aes(x = weeks_count_from_start, y = ave_tRMSSD, color = Group) +
    geom_point(height = 0, width = 0.1, alpha = 0.5) +
    geom_line(aes(group = Group)) +
    facet_wrap(~measure, scales = "free")
```

TODO: this should have some sort of visualisation of the spread around the mean



#### Naive line graph w facets
```{r}
tRMSSD_panas_weeks %>% 
  ggplot() +
    aes(x = weeks_count_from_start, y = tRMSSD_pos, color = participant_id) +
    geom_jitter(height = 0, width = 0.1, alpha = 0.5) +
    geom_line(aes(group = participant_id)) +
    facet_wrap(~Group)
```



# Other stuff
Here's some other stuff you wanted! :)

## actigraphy data
```{r}
# count number of weeks each participant has data from
acti_data %>% 
  distinct(participant_id, weeks_count_from_start) %>% 
  group_by(participant_id) %>% 
  summarise(num_weeks = n())

# count how many entries each participant has within a week
acti_data %>% 
  count(participant_id, weeks_count_from_start)
```

## actigraphy data
```{r}
# count number of weeks each participant has data from
panas_data %>% 
  distinct(participant_id, weeks_count_from_start) %>% 
  group_by(participant_id) %>% 
  summarise(num_weeks = n())

# count how many entries each participant has within a week
panas_data %>% 
  count(participant_id, weeks_count_from_start)
```

# Take a look at files

```{r}

tRMSSD_actigraphy <- read_csv("data/processed/tRMSSD_actigraphy.csv")
view(tRMSSD_actigraphy)


```

